{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "809807168da71634",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:09:30.952371500Z",
     "start_time": "2025-04-20T15:09:30.740294800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17923c5a4ab45cd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:09:31.099862900Z",
     "start_time": "2025-04-20T15:09:30.763523800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400bd35474f3bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:09:31.115357300Z",
     "start_time": "2025-04-20T15:09:30.793602900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filename = \"data\\yes bilder isabelle//2491975_1119775.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec1ca0cdc8c1db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train-Test Split\n",
    "80% - 20%\n",
    "\n",
    "momentan insgesamt je 300 Bilder --> dh. 240 für Training, 60 Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6339ec864b5eac",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a7de67eca2821e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:09:31.116381700Z",
     "start_time": "2025-04-20T15:09:30.822648700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = ['no', 'yes'] # yes: green electro parking spot\n",
    "# 'no' = 0, 'yes' = 1\n",
    "img_size = 224  # Zielgrösse Bilder           \n",
    "\n",
    "def get_data(data_dir):\n",
    "    X = []  # Bilddaten\n",
    "    y = []  # zugehörigen Labels 0 oder 1 \n",
    "\n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img))[..., ::-1]    # Bild einlesen, in RGB umwandeln \n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Bild auf einheitliche Grösse skalieren\n",
    "                X.append(resized_arr)\n",
    "                y.append(class_num)\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler bei {img}: {e}\")\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a0342ff8100491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:09:32.695418700Z",
     "start_time": "2025-04-20T15:09:30.850730500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alle Daten laden \n",
    "train_X, train_y = get_data('dataset/train')   # X=Bild, y=Label \n",
    "val_X, val_y = get_data('dataset/test')        # 0 für no, 1 für yes\n",
    "\n",
    "print(\"Train shape:\", train_X.shape, train_y.shape)\n",
    "print(\"Val shape:\", val_X.shape, val_y.shape)\n",
    "\n",
    "# Beispiel-Labels anzeigen \n",
    "print(\"\\nLabel-Beispiel1:\", train_y[0], \"→\", labels[train_y[0]])\n",
    "print(\"Label-Beispiel2:\", train_y[-1], \"→\", labels[train_y[-1]])\n",
    "\n",
    "# Anzahl Daten\n",
    "print(\"\\nLänge Trainingsdaten:\", len(train_X))   # hier 480 Bilder\n",
    "print(\"Länge Labels:\", len(train_y))   # sollte genauso viele Labels haben wie train_X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b38f30a25a53be",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1faa88131d33e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:09:33.022103200Z",
     "start_time": "2025-04-20T15:09:32.740220500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in train_y:   # train_y sind Labels 0 oder 1 \n",
    "    if i == 0:\n",
    "        l.append(\"no\")\n",
    "    else:\n",
    "        l.append(\"yes\")\n",
    "        \n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(x=l)\n",
    "plt.title(\"Anzahl Bilder pro Klasse (Trainingsdaten)\")\n",
    "plt.xlabel(\"Klasse\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3fe9216ea4a8c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:09:33.354879800Z",
     "start_time": "2025-04-20T15:09:33.027777700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(train_X[0])  # Bilddaten, hier z.B. erstes Bild \n",
    "plt.title(labels[train_y[0]])   # Klassentext: yes or no \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c0ec7eb6e1cd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:09:33.661297500Z",
     "start_time": "2025-04-20T15:09:33.353875100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(train_X[240]) # 241. Bild im Datensatz = 1. yes Bild \n",
    "plt.title(labels[train_y[-1]])  # Label anzeigen: yes or no \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17ab8b5f48a067",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Preprocessing and Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c977aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilder drehen und spiegel aus 1 Orginalbild -> 12 Testbilder \n",
    "def rotate_and_flip_images(x, y):\n",
    "    x_aug, y_aug = [], []\n",
    "    for img, label in zip(x, y):\n",
    "        for k in range(4):  # 0°, 90°, 180°, 270°\n",
    "            rotated = np.rot90(img, k=k)\n",
    "            x_aug.append(rotated); y_aug.append(label)\n",
    "            x_aug.append(np.fliplr(rotated)); y_aug.append(label)  # Horizontal Flip\n",
    "            #x_aug.append(np.flipud(rotated)); y_aug.append(label)  # Vertical Flip\n",
    "    return np.array(x_aug), np.array(y_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3b17abcf77134c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:09:33.898061700Z",
     "start_time": "2025-04-20T15:09:33.668613900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Augmentieren: Drehen und Flippen\n",
    "x_train, y_train = rotate_and_flip_images(train_X, train_y)\n",
    "\n",
    "# Normalisieren --> Pixelwerte von 0-255 enspricht 0-1\n",
    "x_train = x_train / 255.0\n",
    "x_val = val_X / 255.0\n",
    "\n",
    "# Labels als float32 für binary_crossentropy\n",
    "y_train = y_train.astype('float32')\n",
    "y_val = val_y.astype('float32')\n",
    "\n",
    "# Kontrolle\n",
    "print(\"Train X:\", x_train.shape)    # 480 Originalbilder *12 = 5760\n",
    "print(\"Train y:\", y_train.shape)\n",
    "print(\"Val X:\", x_val.shape)        # 120 echte Testbilder \n",
    "print(\"Val y:\", y_val.shape)\n",
    "print(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5ab0fc7c7515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:09:34.052400800Z",
     "start_time": "2025-04-20T15:09:33.909094100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc538866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28dbf2abbdbfd2e9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a239d435c848716b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:09:34.310750800Z",
     "start_time": "2025-04-20T15:09:34.047320500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1. Convolutional Layer\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(224, 224, 3)))\n",
    "model.add(BatchNormalization())  # Normalize after convolution\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "# 2. Convolutional Layer\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())  # Normalize after convolution\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "# 3. Convolutional Layer + Dropout to prevent overfitting\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())  # Normalize after convolution\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Global Average Pooling instead of Flatten\n",
    "model.add(GlobalAveragePooling2D())  # Reduces the size of the output (fewer parameters)\n",
    "\n",
    "# Dense Layer\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "\n",
    "# Output Layer (Sigmoid for binary classification)\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# Optimizer and Callbacks\n",
    "optimizer = Adam(learning_rate=0.0001)  # Adjust learning rate for better convergence\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f4d757e5eb932",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:11:36.287921200Z",
     "start_time": "2025-04-20T15:09:34.275189100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimizer \n",
    "opt = Adam(learning_rate=0.0001)   # Lernrate gibt an wie stark Modell seine Gewichte anpasst \n",
    "\n",
    "# Modell kompilieren \n",
    "model.compile(\n",
    "    optimizer = opt, \n",
    "    loss = 'binary_crossentropy',   # für 2-Klassen Probleme \n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "# Training \n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size = 16, # 32 \n",
    "    epochs = 10,    # max. 50 Runden \n",
    "    validation_data = (x_val, y_val),   # für Modellbewertung \n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]  # beendet Training, wenn sich val_loss 5 Epochen lang nicht mehr verbessert -> verhindert Overfitting \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1399f1272e91e9c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354fd2458c3ca0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:15:57.549699500Z",
     "start_time": "2025-04-20T15:15:56.510935700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Trainingsverlauf aus dem History-Objekt auslesen\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Automatisch richtige Länge der x-Achse\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "# Plot erstellen\n",
    "plt.figure(figsize=(30, 30))\n",
    "\n",
    "# Accuracy-Plot\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Trainingsgenauigkeit')\n",
    "plt.plot(epochs_range, val_acc, label='Validierungsgenauigkeit')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Trainings- und Validierungsgenauigkeit')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Genauigkeit')\n",
    "\n",
    "# Loss-Plot\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Trainingsverlust')\n",
    "plt.plot(epochs_range, val_loss, label='Validierungsverlust')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Trainings- und Validierungsverlust')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Verlust')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6476d90bd9faf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:22:12.122878200Z",
     "start_time": "2025-04-20T15:22:11.689604Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vorhersagen (Wahrscheinlichkeiten zwischen 0 und 1)\n",
    "predictions = model.predict(x_val)\n",
    "\n",
    "# Schwelle: ab 0.5 → Klasse 1 (ja = grüner Parkplatz), sonst Klasse 0\n",
    "predictions = (predictions > 0.5).astype(\"int32\").reshape(-1)\n",
    "\n",
    "# Klassifikationsbericht anzeigen\n",
    "print(classification_report(y_val, predictions, target_names=['kein E-Parkplatz (0)', 'grüner E-Parkplatz (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84627fcb0e4b7ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T15:26:36.198375Z",
     "start_time": "2025-04-20T15:26:35.877740200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix berechnen\n",
    "cm = confusion_matrix(y_val, predictions)\n",
    "\n",
    "# Klassenbezeichnungen\n",
    "labels = ['kein E-Parkplatz', 'grüner E-Parkplatz']\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=labels,\n",
    "            yticklabels=labels)\n",
    "\n",
    "plt.xlabel('Vorhergesagte Klasse')  \n",
    "plt.ylabel('Tatsächliche Klasse')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "# TN    FP\n",
    "# FN    TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea05c160f0594ef",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbdeps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
